<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-tutorial-extras/increasing-reliability">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">Techniques for Improving Model Reliability | Charity Young</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://CharitySarah09.github.io/img/edit.png"><meta data-rh="true" name="twitter:image" content="https://CharitySarah09.github.io/img/edit.png"><meta data-rh="true" property="og:url" content="https://CharitySarah09.github.io/docs/tutorial-extras/increasing-reliability"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Techniques for Improving Model Reliability | Charity Young"><meta data-rh="true" name="description" content="The orginal guide, Techniques for Improving Model Reliability, can be viewed on openai&#x27;s GitHub repository."><meta data-rh="true" property="og:description" content="The orginal guide, Techniques for Improving Model Reliability, can be viewed on openai&#x27;s GitHub repository."><link data-rh="true" rel="icon" href="/img/edit.png"><link data-rh="true" rel="canonical" href="https://CharitySarah09.github.io/docs/tutorial-extras/increasing-reliability"><link data-rh="true" rel="alternate" href="https://CharitySarah09.github.io/docs/tutorial-extras/increasing-reliability" hreflang="en"><link data-rh="true" rel="alternate" href="https://CharitySarah09.github.io/docs/tutorial-extras/increasing-reliability" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.6af49a53.css">
<link rel="preload" href="/assets/js/runtime~main.698c0fee.js" as="script">
<link rel="preload" href="/assets/js/main.554a5f5e.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/edit.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/edit.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Portfolio</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/category/github-quick-start-guide">Work</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/CharitySarah09" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www.linkedin.com/in/charity-young-inc122732/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Linkedin<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/github-quick-start-guide">GitHub Quick Start Guide</a><button aria-label="Toggle the collapsible sidebar category &#x27;GitHub Quick Start Guide&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/editing-samples">Editing Samples</a><button aria-label="Toggle the collapsible sidebar category &#x27;Editing Samples&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/tutorial-extras/copy">How to Format Inputs to ChatGPT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/tutorial-extras/increasing-reliability">Techniques for Improving Model Reliability</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/video--graphics">Video &amp; Graphics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Video &amp; Graphics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/about-me">About</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/editing-samples"><span itemprop="name">Editing Samples</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Techniques for Improving Model Reliability</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Techniques for Improving Model Reliability</h1><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_S0QG"><p>The orginal guide, <a href="https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md" target="_blank" rel="noopener noreferrer">Techniques for Improving Model Reliability</a>, can be viewed on openai&#x27;s GitHub repository.</p></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="complex-tasks">Complex Tasks<a href="#complex-tasks" class="hash-link" aria-label="Direct link to Complex Tasks" title="Direct link to Complex Tasks">​</a></h2><p>If asked to multiply 13 by 17, would the answer immediately pop into your mind? It probably won&#x27;t for most individuals, but that doesn&#x27;t mean humans are incapable of two-digit multiplication. Given pen, paper and a few seconds, it&#x27;s not too difficult to solve 13x17= 130 + 70 + 21 = 221.</p><p>Similarly, if GPT-3 receives a task that&#x27;s too complex to compute within the time alloted for the current token, it may produce an incorrect guess. Also like people, this doesn&#x27;t necessarily mean the model can&#x27;t handle the task. Given some time and several rounds to reason through the task, the model could provide a more accurate answer.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-1-math-problem">Example 1: Math Problem<a href="#example-1-math-problem" class="hash-link" aria-label="Direct link to Example 1: Math Problem" title="Direct link to Example 1: Math Problem">​</a></h3><p>For example, if you ask text-davinci-002 the following math problem, it answers incorrectly:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Q: A juggler has 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">A:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">There are 8 blue golf balls.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Does this mean that GPT-3 can&#x27;t do simple math problems? No, it only highlights the need for instructive and precise prompts. As seen below, when the model is prompted with &quot;Let&#x27;s think step by step&quot; the correct answer is given.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Q: A juggler has 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">A: Let&#x27;s think step by step.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">There are 16 balls in total. </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Half of the balls are golf balls. </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">That means that there are 8 golf balls. </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Half of the golf balls are blue. </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">That means that there are 4 blue golf balls.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>One should not assume from a single example that the prompt, &quot;Let&#x27;s think step by step&quot;, will produced accurate results for similar math problems or it was an isolated case. Still, further review did prove it&#x27;s usefullness. It was found that when used with word math problems, the prompt increased GPT-3&#x27;s accuracy rate from 18% to 79%.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="context-and-model-capabilities">Context and Model Capabilities<a href="#context-and-model-capabilities" class="hash-link" aria-label="Direct link to Context and Model Capabilities" title="Direct link to Context and Model Capabilities">​</a></h2><p>A common misconception about GPT-3 is that model capabilities are fixed across all contexts (e.g. if GPT-3 gets a simple logic question wrong, then it must be incapable of simple logic). On the contrary, sometimes incorrect answers can be resolved with a prompt that provides more direction for problem solving as illustrated from the math problem in Example 1.</p><p>The following methods for improving the reliability of large language models working on complex tasks will be reviewed:</p><ul><li>Give clearer instructions.</li><li>Split complex tasks into simpler subtasks.</li><li>Structure the instructions to keep the model on task.</li><li>Prompt the model to explain before answering.</li><li>Fine-tune custom models to maximize performance.</li></ul><p>Some of these techniques are geared towards specific problem types, nonetheless the framework for most are developed upon general model principles that can be applied to a range of tasks.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="simplify-a-task">Simplify a Task<a href="#simplify-a-task" class="hash-link" aria-label="Direct link to Simplify a Task" title="Direct link to Simplify a Task">​</a></h2><p>One strategy for allowing the model sufficient time to solve a problem is by spliting the task into smaller parts so it requires several steps to reach the answer.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-2-splitting-the-task">Example 2: Splitting the Task<a href="#example-2-splitting-the-task" class="hash-link" aria-label="Direct link to Example 2: Splitting the Task" title="Direct link to Example 2: Splitting the Task">​</a></h3><p>In this task, the model is asked to answer a multiple-choice question taken from the game, Clue. In the first prompt, text-davinci-002 isn&#x27;t able to combine clues 3 and 5 to solve the problem. </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Use the following clues to answer the following multiple-choice question.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clues:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Miss Scarlett was the only person in the lounge.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. The person with the pipe was in the kitchen.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Colonel Mustard was the only person in the observatory.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Professor Plum was not in the library nor the billiard room.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. The person with the candlestick was in the observatory.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Question: Was Colonel Mustard in the observatory with the candlestick?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(a) Yes; Colonel Mustard was in the observatory with the candlestick</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(b) No; Colonel Mustard was not in the observatory with the candlestick</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Solution:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>By breaking the question down into multiple steps, the model can process the different pieces of information and their relationship better. This time the task consists of three parts: </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Use the following clues to answer the following multiple-choice question, applying the following procedure:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(1) First, go through the clues one by one and consider whether the clue is potentially relevant</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(2) Second, combine the relevant clues to reason out the answer to the question</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(3) Third, map the answer to one of the multiple choice answers: either (a), (b), or (c)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clues:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Miss Scarlett was the only person in the lounge.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. The person with the pipe was in the kitchen.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Colonel Mustard was the only person in the observatory.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Professor Plum was not in the library nor the billiard room.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. The person with the candlestick was in the observatory.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Question: Was Colonel Mustard in the observatory with the candlestick?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(a) Yes; Colonel Mustard was in the observatory with the candlestick</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(b) No; Colonel Mustard was not in the observatory with the candlestick</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Solution:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(1) First, go through the clues one by one and consider whether the clue is potentially relevant:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clue 1: Miss Scarlett was the only person in the lounge. This clue is not relevant.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clue 2: The person with the pipe was in the kitchen. This clue is not relevant.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clue 3: Colonel Mustard was the only person in the observatory. This clue is relevant.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clue 4: Professor Plum was not in the library nor the billiard room. This clue is not relevant.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clue 5: The person with the candlestick was in the observatory. This clue is relevant.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(2) Second, combine the relevant clues to reason out the answer to the question:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Clue 3 and Clue 5 both say that the person with the candlestick was in the observatory. Colonel Mustard was the only person in the observatory, so Colonel Mustard was the person with the candlestick.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(3) Third, write the final answer:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(a) Yes; Colonel Mustard was in the observatory with the candlestick</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Giving a model time and space to solve a problem while guiding its reasoning, improves the accuracy. Another benefit of splitting instuctions into smaller subtasks is that it can help the model stay on track through each step of the process. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-3-splitting-the-task">Example 3: Splitting the Task<a href="#example-3-splitting-the-task" class="hash-link" aria-label="Direct link to Example 3: Splitting the Task" title="Direct link to Example 3: Splitting the Task">​</a></h3><p>The text used below explains that statistics is a science that studies the variability, collection, organization, analysis, interpretation, and presentation of data, as well as the random process that generates them following the laws of probability.</p><p>If text-davinci-001 is asked to summarize this text in its original language, the model can lapse back into English:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Summarize the text using the original language of the text. The summary should be one sentence long.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Text:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;La estadística (la forma femenina del término alemán Statistik, derivado a su vez del italiano statista, &quot;hombre de Estado&quot;)​ es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.​ La estadística es una ciencia formal deductiva, con un conocimiento propio, dinámico y en continuo desarrollo obtenido a través del método científico formal. En ocasiones, las ciencias fácticas necesitan utilizar técnicas estadísticas durante su proceso de investigación factual, con el fin de obtener nuevos conocimientos basados en la experimentación y en la observación. En estos casos, la aplicación de la estadística permite el análisis de datos provenientes de una muestra representativa, que busca explicar las correlaciones y dependencias de un fenómeno físico o natural, de ocurrencia en forma aleatoria o condicional.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Summary:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The text explains that statistics is a science that studies the variability, collection, organization, analysis, interpretation, and presentation of data, as well as the random process that generates them following the laws of probability.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now, when the model is directed to first identify the language of the text and then summarize, it becomes more reliable:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">First, identify the language of the text. Second, summarize the text using the original language of the text. The summary should be one sentence long.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Text:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;La estadística (la forma femenina del término alemán Statistik, derivado a su vez del italiano statista, &quot;hombre de Estado&quot;)​ es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.​ La estadística es una ciencia formal deductiva, con un conocimiento propio, dinámico y en continuo desarrollo obtenido a través del método científico formal. En ocasiones, las ciencias fácticas necesitan utilizar técnicas estadísticas durante su proceso de investigación factual, con el fin de obtener nuevos conocimientos basados en la experimentación y en la observación. En estos casos, la aplicación de la estadística permite el análisis de datos provenientes de una muestra representativa, que busca explicar las correlaciones y dependencias de un fenómeno físico o natural, de ocurrencia en forma aleatoria o condicional.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Language:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Spanish</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">La estadística es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="explain-before-answering-prompts">Explain before Answering Prompts<a href="#explain-before-answering-prompts" class="hash-link" aria-label="Direct link to Explain before Answering Prompts" title="Direct link to Explain before Answering Prompts">​</a></h2><p>Another technique for improving the reliability is prompting the model to rationalize before providing a final answer. By requiring the model to reason, in essence &quot;thinking aloud&quot;, the probability of a correct answer greatly increases. The methods that are different variation of Explain before answering prompts. The research that follows employ different variations of this method.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="zero-shot">Zero-shot<a href="#zero-shot" class="hash-link" aria-label="Direct link to Zero-shot" title="Direct link to Zero-shot">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="research">Research<a href="#research" class="hash-link" aria-label="Direct link to Research" title="Direct link to Research">​</a></h4><p>According to Kojima&#x27;s et al. findings (2022) on the zero-shot method, prepending answers with &quot;Let&#x27;s think stey by step&quot; was the easiest way to prompt a model to reason out the answer. Figure 1 below illustrates its use in their study:</p><p><img loading="lazy" alt="img alt" src="/assets/images/guideone-976154a19c0da6aff171f2b41e5aae73.png" width="812" height="318" class="img_ev3q"></p><p>Figure 1: Zero-shot prompting</p><p>Source: Large Language Models are Zero-shot Reasoners by Takeshi Kojima et al. (2022)</p><p>As noted earlier, including the prompt &quot;Let&#x27;s think step by step&quot; in the task message quadrupled the accuracy from 18% t0 79% for the MultiArith math dataset. Although, it works well on math problems, it&#x27;s not as effective on all task. Researchers found it most helpful for multi-step artithmetic, symbolic reasoning, strategy and other reasoning problems. It did not fair so well with simple math problems or common sense questions. The prompt probably won&#x27;t increase accuracy with other types of non-reasoning tasks either. Please see the <a href="#appendix">appendix</a> for additional charts and tables reflecting the findings from Kojima&#x27;s study or read the full <a href="https://arxiv.org/abs/2205.11916" target="_blank" rel="noopener noreferrer">article</a>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="application">Application<a href="#application" class="hash-link" aria-label="Direct link to Application" title="Direct link to Application">​</a></h4><p>&quot;Let&#x27;s think step by step&quot; is rather generic though. Depending upon the task, consider experimenting with different versions of this instruction. It&#x27;s possible to get better results with more explicit directions that have been customized. For example, the prompt can be structured to address different parts of content: First, think step by step about why X might be true. Second, think step by step about why Y might be true. Third, think step by step about whether X or Y makes more sense. Additionally, you can provide the model with an example format to so it stays on task. See the example below.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="example-4-zero-shot-prompt">Example 4: Zero-shot Prompt<a href="#example-4-zero-shot-prompt" class="hash-link" aria-label="Direct link to Example 4: Zero-shot Prompt" title="Direct link to Example 4: Zero-shot Prompt">​</a></h5><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Using the IRS guidance below, answer the following questions using this format:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(1) For each criterion, determine whether it is met by the vehicle purchase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- {Criterion} Let&#x27;s think step by step. {explanation} {yes or no, or if the question does not apply then N/A}.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(2) After considering each criterion in turn, phrase the final answer as &quot;Because of {reasons}, the answer is likely {yes or no}.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">IRS guidance:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">You may be eligible for a federal tax credit under Section 30D if you purchased a car or truck that meets the following criteria:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Does the vehicle have at least four wheels?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Does the vehicle weigh less than 14,000 pounds?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Does the vehicle draw energy from a battery with at least 4 kilowatt hours that may be recharged from an external source?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Was the vehicle purchased in a year before 2022?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - If so, has the manufacturer sold less than 200,000 qualifying vehicles? (Tesla and GM have sold more than 200,000 qualifying vehicles.)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Was the vehicle purchased in a year after 2022?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - If so, is the vehicle present in the following list of North American-assembled vehicles? (The only electric vehicles assembled in North America are the Audi Q5, BMW 330e, BMW X5, Chevrolet Bolt EUV, Chevrolet Bolt EV, Chrysler Pacifica PHEV, Ford Escape PHEV, Ford F Series, Ford Mustang MACH E, Ford Transit Van, GMC Hummer Pickup, GMC Hummer SUV, Jeep Grand Cherokee PHEV, Jeep Wrangler PHEV, Lincoln Aviator PHEV, Lincoln Corsair Plug-in, Lucid Air, Nissan Leaf, Rivian EDV, Rivian R1S, Rivian R1T, Tesla Model 3, Tesla Model S, Tesla Model X, Tesla Model Y, Volvo S60, BMW 330e, Bolt EV, Cadillac Lyriq, Mercedes EQS SUV, and Nissan Leaf.)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Question: Can I claim a federal tax credit for my Toyota Prius Prime bought in 2021?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Solution:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(1) For each criterion, determine whether it is met by the vehicle purchase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Does the vehicle have at least four wheels? Let&#x27;s think step by step.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> The Toyota Prius Prime has four wheels, so the answer is yes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Does the vehicle weigh less than 14,000 pounds? Let&#x27;s think step by step. The Toyota Prius Prime weighs less than 14,000 pounds, so the answer is yes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Does the vehicle draw energy from a battery with at least 4 kilowatt hours that may be recharged from an external source? Let&#x27;s think step by step. The Toyota Prius Prime has a battery with at least 4 kilowatt hours that may be recharged from an external source, so the answer is yes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Was the vehicle purchased in a year before 2022? Let&#x27;s think step by step. The Toyota Prius Prime was purchased in 2021, which is before 2022, so the answer is yes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Was the vehicle purchased in a year after 2022? N/A</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- If so, is the vehicle present in the following list of North American-assembled vehicles? N/A</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(2) After considering each criterion in turn, phrase the final answer as &quot;Because of {reasons}, the answer is likely {yes or no}.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Because the Toyota Prius Prime meets all of the criteria for a federal tax credit, the answer is likely yes.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="few-shot-example">Few-shot Example<a href="#few-shot-example" class="hash-link" aria-label="Direct link to Few-shot Example" title="Direct link to Few-shot Example">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="research-1">Research<a href="#research-1" class="hash-link" aria-label="Direct link to Research" title="Direct link to Research">​</a></h4><p>Similar to the zero-shot method, few-shot directs the model to reason out the answers. However, the few-shot method demonstrates the appropriate problem solving steps with several examples. Jason Wei and Denny Zhou  display in their study how the few-show-chain-of thought-prompt works(Language Models Perform Reasoning via Chain of Thought, 2022): </p><p><img loading="lazy" alt="img alt" src="/assets/images/guidetwo-43a211aed6e982fcedd7a8a721f478c2.png" width="875" height="432" class="img_ev3q"></p><p>Figure 2:  Example of few-shot prompting</p><p>Source: Chain of Thought Prompting Elicits Reasoning in Large Language Models by Jason Wei and Denny Zhou et al.</p><hr><p>Here are more examples of reasoning chains written by human labelers in the study. </p><p><img loading="lazy" alt="img alt" src="/assets/images/guidethree-3255b79267b3de0c7bc059bc079a3ef5.png" width="604" height="485" class="img_ev3q"></p><p>Figure 3: Reasoning chains</p><p>Source: Chain of Thought Prompting Elicits Reasoning in Large Language Models by Jason Wei and Denny Zhou et al.</p><p>When using grade school math problems as tasks, researchers found that chain-of-though prompting tripled the accuracy from 18% to 57%. The method was also applied to questions related to sports understanding, coin flip tracking and last letter concatenation. The train-of-thought prompt lifted the accuracy rates for these tasks as well, and the model did not require many examples (around 8 or less) to saturate the performance gains in most cases. Please see the appendix for additional charts and tables reflecting the findings or read the full<a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html" target="_blank" rel="noopener noreferrer">article</a>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="application-1">Application<a href="#application-1" class="hash-link" aria-label="Direct link to Application" title="Direct link to Application">​</a></h4><p>Compared to the &quot;Let&#x27;s think step by step&quot; technique, the few-shot example approach allows for more control as the format, length and style of reasoning can be specified to the model before it makes an attempt to answer the question. In cases where the model&#x27;s reasoning is incorrect or to simple/shallow, this method can be particularly helpful. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuned">Fine-tuned<a href="#fine-tuned" class="hash-link" aria-label="Direct link to Fine-tuned" title="Direct link to Fine-tuned">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="research-2">Research<a href="#research-2" class="hash-link" aria-label="Direct link to Research" title="Direct link to Research">​</a></h4><p>In general, maximum performance on a task involves fine-tuning a custom model. However, the process of training the model may take thousdands of example explanations which are costly to write. </p><p>To overcome this, Eric Zelikman and Yuhua et al. (2022) Wu have developed a clever procedure whereby a dataset of explanations are generated from a few-shot prompt. The dataset is used to fine-tune the model.  </p><p>Using a few-shot prompt, the model is instructed to generate an answer that includes an explanation for its choice. Only the explanations for correct answers are kept for fine-tuning the model. Next, the prompts for incorrect answers are edited by including the explanations provided in the corrects answers, and then the task is performed once again. If it generates a correct answer with the second attempt, the additional correct explanation is collected as well. The authors call this STaR (Self-taught Reasoner): </p><p><img loading="lazy" alt="img alt" src="/assets/images/guidefour-6b00d65f36e8f15a914af23c4c06aefa.png" width="819" height="351" class="img_ev3q"></p><p>Figure 4: How STaR works</p><p>Source: STaR Bootstrapping Reasoning with Reasoning by Eric Zelikman &amp; Yujuai Wu et al. </p><p>It is like a farmer only taking the seeds from the healthy and strong fruit and then planting these seeds for the next harvest. It&#x27;s a form of quality control. When the authors applied this technique to a Common Sense Q&amp;A dataset, they found that STaR (78%) outperformed both chain-of-thought prompting (37%) and fine-tuning (37%).  The full article can be read <a href="https://arxiv.org/abs/2203.14465" target="_blank" rel="noopener noreferrer">here</a>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="application-2">Application<a href="#application-2" class="hash-link" aria-label="Direct link to Application" title="Direct link to Application">​</a></h4><p>The STaR concept can be generalized for other purposes beyond explanation writing. For example, large quantities of unstructured text can be trained by using a prompt to extract a structured dataset from the unstructured text and then fine-tune a custom model with the structured dataset. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="appendix">Appendix<a href="#appendix" class="hash-link" aria-label="Direct link to Appendix" title="Direct link to Appendix">​</a></h2><p><img loading="lazy" alt="img alt" src="/assets/images/guidefive-8559d68495ef0af59245adb2903eb319.png" width="880" height="292" class="img_ev3q"></p><p>Figure 5: Accuracy rates for different prompts answering MultiArith dataset with Text-davinci-002</p><p>Source:  Large Language Models are Zero-shot Reasoners by Takeshi Kojima et al. (2022)</p><hr><p><img loading="lazy" alt="img alt" src="/assets/images/guidesix-fe9220a195b28d7a470c6fc2767832dd.png" width="769" height="299" class="img_ev3q"></p><p>Figure 6: Improvement from Chain thought prompting</p><p>Source: Chain of Thought Prompting Elicits Reasoning in Large Language Models by Jason Wei and Denny Zhou et al. (2002)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bibliography">Bibliography<a href="#bibliography" class="hash-link" aria-label="Direct link to Bibliography" title="Direct link to Bibliography">​</a></h2><p>Kojima, T., Gu, S., Reid, M., Matsuo, Y., &amp; Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. ArXiv (Cornell University). <a href="https://doi.org/10.48550/arxiv.2205.11916" target="_blank" rel="noopener noreferrer">https://doi.org/10.48550/arxiv.2205.11916</a></p><p>Language Models Perform Reasoning via Chain of Thought. (2022, May 11). <a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html" target="_blank" rel="noopener noreferrer">https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html</a></p><p>Zelikman, E., Wu, Y., Mu, J., &amp; Goodman, N. D. (2022). STaR: Bootstrapping reasoning with reasoning. In arXiv <!-- -->[cs.LG]<!-- -->. <a href="http://arxiv.org/abs/2203.14465" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2203.14465</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/CharitySarah09/CharitySarah09.github.io/tree/main/packages/create-docusaurus/templates/shared/docs/tutorial-extras/increasing-reliability.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/tutorial-extras/copy"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">How to Format Inputs to ChatGPT</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/category/video--graphics"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Video &amp; Graphics</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#complex-tasks" class="table-of-contents__link toc-highlight">Complex Tasks</a><ul><li><a href="#example-1-math-problem" class="table-of-contents__link toc-highlight">Example 1: Math Problem</a></li></ul></li><li><a href="#context-and-model-capabilities" class="table-of-contents__link toc-highlight">Context and Model Capabilities</a></li><li><a href="#simplify-a-task" class="table-of-contents__link toc-highlight">Simplify a Task</a><ul><li><a href="#example-2-splitting-the-task" class="table-of-contents__link toc-highlight">Example 2: Splitting the Task</a></li><li><a href="#example-3-splitting-the-task" class="table-of-contents__link toc-highlight">Example 3: Splitting the Task</a></li></ul></li><li><a href="#explain-before-answering-prompts" class="table-of-contents__link toc-highlight">Explain before Answering Prompts</a><ul><li><a href="#zero-shot" class="table-of-contents__link toc-highlight">Zero-shot</a></li><li><a href="#few-shot-example" class="table-of-contents__link toc-highlight">Few-shot Example</a></li><li><a href="#fine-tuned" class="table-of-contents__link toc-highlight">Fine-tuned</a></li></ul></li><li><a href="#appendix" class="table-of-contents__link toc-highlight">Appendix</a></li><li><a href="#bibliography" class="table-of-contents__link toc-highlight">Bibliography</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Charity Young Portfolio. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.698c0fee.js"></script>
<script src="/assets/js/main.554a5f5e.js"></script>
</body>
</html>